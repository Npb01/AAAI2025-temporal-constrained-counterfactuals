{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27d31fe5-93bc-45e5-b309-399034c0a08f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m             df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malphabet_coverage\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m subdir\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     14\u001b[0m             dfs\u001b[38;5;241m.\u001b[39mappend(df)\n\u001b[1;32m---> 15\u001b[0m df1 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdfs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults/bpic2012_O_ACCEPTED-COMPLETE\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     19\u001b[0m folders \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults/bpic2012_O_ACCEPTED-COMPLETE/10\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     20\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults/bpic2012_O_ACCEPTED-COMPLETE/25\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     21\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults/bpic2012_O_ACCEPTED-COMPLETE/50\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     22\u001b[0m           ] \n",
      "File \u001b[1;32mc:\\Users\\20193723\\OneDrive - TU Eindhoven\\Documents\\Seminar PA\\AAAI2025-temporal-constrained-counterfactuals\\.venv\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\20193723\\OneDrive - TU Eindhoven\\Documents\\Seminar PA\\AAAI2025-temporal-constrained-counterfactuals\\.venv\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:368\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mconcat\u001b[39m(\n\u001b[0;32m    148\u001b[0m     objs: Iterable[NDFrame] \u001b[38;5;241m|\u001b[39m Mapping[HashableT, NDFrame],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    157\u001b[0m     copy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    158\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m    159\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;124;03m    Concatenate pandas objects along a particular axis.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;124;03m    1   3   4\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 368\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    369\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    370\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    371\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    373\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    374\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    375\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    376\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    377\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    378\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32mc:\\Users\\20193723\\OneDrive - TU Eindhoven\\Documents\\Seminar PA\\AAAI2025-temporal-constrained-counterfactuals\\.venv\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:425\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    422\u001b[0m     objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 425\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    428\u001b[0m     objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs))\n",
      "\u001b[1;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "path = \"results/synthetic_data\"\n",
    "folders = [\"results/synthetic_data/10%\",\n",
    "           \"results/synthetic_data/25%\",\n",
    "           \"results/synthetic_data/50%\"\n",
    "          ]\n",
    "dfs = []\n",
    "for subdir, dirs, files in os.walk(path+'/'):\n",
    "    for file in files:\n",
    "        if 'cfeval' in file:\n",
    "            df = pd.read_csv(os.path.join(subdir,file))\n",
    "            df['alphabet_coverage'] = subdir.split('/')[-1]\n",
    "            dfs.append(df)\n",
    "df1 = pd.concat(dfs)\n",
    "\n",
    "\n",
    "path = \"results/bpic2012_O_ACCEPTED-COMPLETE\"\n",
    "folders = [\"results/bpic2012_O_ACCEPTED-COMPLETE/10%\",\n",
    "           \"results/bpic2012_O_ACCEPTED-COMPLETE/25%\",\n",
    "           \"results/bpic2012_O_ACCEPTED-COMPLETE/50%\"\n",
    "          ] \n",
    "dfs = []\n",
    "for subdir, dirs, files in os.walk(path+'/'):\n",
    "    for file in files:\n",
    "        if 'cfeval' in file:\n",
    "            df = pd.read_csv(os.path.join(subdir,file))\n",
    "            df['alphabet_coverage'] = subdir.split('/')[-1]\n",
    "            dfs.append(df)\n",
    "df2 = pd.concat(dfs)\n",
    "\n",
    "\n",
    "\n",
    "path = \"results/BPIC17_O_ACCEPTED/\"\n",
    "folders = [\"results/BPIC17_O_ACCEPTED/10%\",\n",
    "           \"results/BPIC17_O_ACCEPTED/25%\",\n",
    "           \"results/BPIC17_O_ACCEPTED/50%\"\n",
    "          ]\n",
    "dfs = []\n",
    "for subdir, dirs, files in os.walk(path+'/'):\n",
    "    for file in files:\n",
    "        if 'cfeval' in file:\n",
    "            df = pd.read_csv(os.path.join(subdir,file))\n",
    "            df['alphabet_coverage'] = subdir.split('/')[-1]\n",
    "            dfs.append(df)\n",
    "df3 = pd.concat(dfs)\n",
    "\n",
    "df1.loc[df1['method'] == 'genetic_ltlf_baseline_operators', 'heuristic'] = 'genetic_ltlf_baseline_operators'\n",
    "df2.loc[df2['method'] == 'genetic_ltlf_baseline_operators', 'heuristic'] = 'genetic_ltlf_baseline_operators'\n",
    "df3.loc[df3['method'] == 'genetic_ltlf_baseline_operators', 'heuristic'] = 'genetic_ltlf_baseline_operators'\n",
    "\n",
    "df1.loc[df1['heuristic'] == 'mar', 'heuristic'] = 'mutate_retry_baseline'\n",
    "df2.loc[df2['heuristic'] == 'mar', 'heuristic'] = 'mutate_retry_baseline'\n",
    "df3.loc[df3['heuristic'] == 'mar', 'heuristic'] = 'mutate_retry_baseline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141e6814-14bc-4e1c-bd4c-568fe870ab6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import friedmanchisquare, wilcoxon\n",
    "import statsmodels.stats.multitest as smm\n",
    "import numpy as np\n",
    "\n",
    "# Assuming df1, df2, df3 are your DataFrames for the three datasets\n",
    "dfs = [df1, df2, df3]\n",
    "results = []\n",
    "\n",
    "# Preprocess the data and calculate mean values for grouping\n",
    "for i, df in enumerate(dfs, 1):\n",
    "    df_groupby = df.groupby(['heuristic', 'prefix_length', 'desired_nr_of_cfs', 'alphabet_coverage']).mean(numeric_only=True).reset_index()\n",
    "    df_groupby['dataset'] = df['dataset'].iloc[0]\n",
    "    results.append(df_groupby)\n",
    "\n",
    "# Combine all datasets into a single DataFrame\n",
    "combined_df = pd.concat(results)\n",
    "combined_df = combined_df.rename(columns={'sat_score':'conformance', 'distance_l2j':'distance', \n",
    "                                          'implausibility_sum':'implausibility', 'avg_nbr_changes_per_cf':'sparsity', \n",
    "                                          'diversity_l2j':'diversity'})\n",
    "combined_df['hit_rate'] = combined_df['generated_cfs'] / combined_df['desired_nr_of_cfs']\n",
    "\n",
    "# List of metrics\n",
    "metrics = ['distance', 'sparsity', 'implausibility', 'conformance', 'diversity', 'hit_rate', 'runtime']\n",
    "\n",
    "friedman_results = {}\n",
    "pairwise_results = {}\n",
    "\n",
    "# Perform tests for each dataset and alphabet_coverage\n",
    "for dataset in combined_df['dataset'].unique():\n",
    "    dataset_df = combined_df[combined_df['dataset'] == dataset]\n",
    "    friedman_results[dataset] = {}\n",
    "    pairwise_results[dataset] = {}\n",
    "\n",
    "    for alphabet_coverage in dataset_df['alphabet_coverage'].unique():\n",
    "        ac_df = dataset_df[dataset_df['alphabet_coverage'] == alphabet_coverage]\n",
    "        friedman_results[dataset][alphabet_coverage] = {}\n",
    "        pairwise_results[dataset][alphabet_coverage] = {}\n",
    "\n",
    "        for metric in metrics:\n",
    "            # Ensure uniqueness by grouping and averaging\n",
    "            df_pivot = ac_df.groupby(['prefix_length', 'desired_nr_of_cfs', 'heuristic'])[metric].mean().unstack()\n",
    "\n",
    "            # Drop rows with any NaN values to ensure equal N for all groups\n",
    "            df_pivot = df_pivot.dropna()\n",
    "\n",
    "            if len(df_pivot.columns) < 2:\n",
    "                continue  # Skip if there are less than 2 methods to compare\n",
    "\n",
    "            # Perform Friedman test\n",
    "            stat, p_value = friedmanchisquare(*[df_pivot[method] for method in df_pivot.columns])\n",
    "            friedman_results[dataset][alphabet_coverage][metric] = p_value\n",
    "\n",
    "            if p_value < 0.05:\n",
    "                heuristics = df_pivot.columns\n",
    "                p_values = []\n",
    "                pairs = []\n",
    "\n",
    "                for i in range(len(heuristics)):\n",
    "                    for j in range(i + 1, len(heuristics)):\n",
    "                        h1 = heuristics[i]\n",
    "                        h2 = heuristics[j]\n",
    "                        data_h1 = df_pivot[h1]\n",
    "                        data_h2 = df_pivot[h2]\n",
    "\n",
    "                        if np.array_equal(data_h1, data_h2):\n",
    "                            p_value = 1.0\n",
    "                        else:\n",
    "                            try:\n",
    "                                # Perform Wilcoxon signed-rank test\n",
    "                                stat, p_value = wilcoxon(data_h1, data_h2, zero_method='wilcox')\n",
    "                            except ValueError:\n",
    "                                p_value = np.nan\n",
    "                        p_values.append(p_value)\n",
    "                        pairs.append((h1, h2))\n",
    "\n",
    "                # Perform multiple comparisons correction (e.g., Bonferroni correction)\n",
    "                corrected_p_vals = smm.multipletests(p_values, alpha=0.05, method='bonferroni')[1]\n",
    "                pairwise_results[dataset][alphabet_coverage][metric] = dict(zip(pairs, corrected_p_vals))\n",
    "\n",
    "# Initialize a dictionary to store ranks\n",
    "ranks = {dataset: {alphabet_coverage: {metric: {} for metric in metrics} \n",
    "                   for alphabet_coverage in combined_df['alphabet_coverage'].unique()} \n",
    "         for dataset in combined_df['dataset'].unique()}\n",
    "\n",
    "# Assign ranks based on significant differences\n",
    "for dataset in combined_df['dataset'].unique():\n",
    "    for alphabet_coverage in combined_df['alphabet_coverage'].unique():\n",
    "        dataset_ac_df = combined_df[(combined_df['dataset'] == dataset) & \n",
    "                                    (combined_df['alphabet_coverage'] == alphabet_coverage)]\n",
    "\n",
    "        for metric in metrics:\n",
    "            df_pivot = dataset_ac_df.groupby(['prefix_length', 'desired_nr_of_cfs', 'heuristic'])[metric].mean().unstack()\n",
    "            df_pivot = df_pivot.dropna()\n",
    "\n",
    "            if len(df_pivot.columns) < 2:\n",
    "                continue  # Skip if there are less than 2 methods to compare\n",
    "\n",
    "            methods = df_pivot.columns\n",
    "\n",
    "            if friedman_results[dataset][alphabet_coverage][metric] < 0.05:\n",
    "                for method in methods:\n",
    "                    ranks[dataset][alphabet_coverage][metric][method] = 1  # Initial rank\n",
    "\n",
    "                for (h1, h2), corrected_p_val in pairwise_results[dataset][alphabet_coverage][metric].items():\n",
    "                    if corrected_p_val < 0.05:\n",
    "                        if df_pivot[h1].mean() < df_pivot[h2].mean():\n",
    "                            ranks[dataset][alphabet_coverage][metric][h2] += 1\n",
    "                        else:\n",
    "                            ranks[dataset][alphabet_coverage][metric][h1] += 1\n",
    "            else:\n",
    "                for method in methods:\n",
    "                    ranks[dataset][alphabet_coverage][metric][method] = 1  # Same rank if no significant difference\n",
    "\n",
    "# Create a DataFrame to store the ranks\n",
    "rank_table = pd.DataFrame(columns=['dataset', 'metric', 'alphabet_coverage', 'heuristic', 'rank'])\n",
    "\n",
    "# Populate the DataFrame with ranks\n",
    "for dataset in combined_df['dataset'].unique():\n",
    "    for alphabet_coverage in combined_df['alphabet_coverage'].unique():\n",
    "        dataset_ac_df = combined_df[(combined_df['dataset'] == dataset) & \n",
    "                                    (combined_df['alphabet_coverage'] == alphabet_coverage)]\n",
    "        for metric in metrics:\n",
    "            df_pivot = dataset_ac_df.groupby(['prefix_length', 'desired_nr_of_cfs', 'heuristic'])[metric].mean().unstack()\n",
    "            df_pivot = df_pivot.dropna()\n",
    "            for (prefix_length, desired_nr_of_cfs), row in df_pivot.iterrows():\n",
    "                for heuristic, value in row.items():\n",
    "                    rank_table = rank_table.append({\n",
    "                        'dataset': dataset,\n",
    "                        'metric': metric,\n",
    "                        'alphabet_coverage': alphabet_coverage,\n",
    "                        'heuristic': heuristic,\n",
    "                        'rank': ranks[dataset][alphabet_coverage][metric][heuristic]\n",
    "                    }, ignore_index=True)\n",
    "\n",
    "# Pivot the rank_table to show ranks for each dataset, heuristic, metric, and alphabet coverage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50092c30-dd3d-4ca2-9e04-43294f4b78a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_table = rank_table.pivot_table(index=['dataset', 'alphabet_coverage','metric'], columns='heuristic', values='rank')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27eec66d-e7f6-491f-bb36-1781ddb67db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_table.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d4a75d-8132-4a0a-b26e-6f5fd8b58068",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "pivot_table = pivot_table[['genetic_ltlf_baseline_operators','mutate_retry_baseline', 'heuristic_1',\n",
    "       'heuristic_2']]\n",
    "display(HTML(pivot_table.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7946908d-acbc-4340-b836-3c40057ecca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df1, df2, df3 are your DataFrames for the three datasets\n",
    "dfs = [df1, df2, df3]\n",
    "results = []\n",
    "for i, df in enumerate(dfs, 1):\n",
    "    df_groupby = df.groupby(['heuristic', 'prefix_length', 'desired_nr_of_cfs']).mean(numeric_only=True).reset_index()\n",
    "    df_groupby['dataset'] = df['dataset'][1].unique()[0]\n",
    "    results.append(df_groupby)\n",
    "\n",
    "\n",
    "# Combine all datasets into a single DataFrame\n",
    "combined_df = pd.concat(results)\n",
    "combined_df = pd.concat(results)\n",
    "combined_df = combined_df.rename(columns={'sat_score':'conformance','distance_l2j':'distance','implausibility_sum':'implausibility'\n",
    "                                       ,'avg_nbr_changes_per_cf':'sparsity','diversity_l2j':'diversity'})\n",
    "combined_df['hit_rate'] = combined_df['generated_cfs']/combined_df['desired_nr_of_cfs']\n",
    "# List of metrics\n",
    "metrics = ['distance', 'sparsity', 'implausibility', 'conformance', 'diversity', 'hit_rate', 'runtime']\n",
    "\n",
    "friedman_results = {}\n",
    "pairwise_results = {}\n",
    "\n",
    "# Perform tests for each dataset\n",
    "for dataset in combined_df['dataset'].unique():\n",
    "    dataset_df = combined_df[combined_df['dataset'] == dataset]\n",
    "    friedman_results[dataset] = {}\n",
    "    pairwise_results[dataset] = {}\n",
    "\n",
    "    for metric in metrics:\n",
    "        df_pivot = dataset_df.pivot(index=['prefix_length', 'desired_nr_of_cfs'], columns='heuristic', values=metric)\n",
    "\n",
    "        # Drop rows with any NaN values to ensure equal N for all groups\n",
    "        df_pivot = df_pivot.dropna()\n",
    "\n",
    "        if len(df_pivot.columns) < 2:\n",
    "            continue  # Skip if there are less than 2 methods to compare\n",
    "\n",
    "        # Perform Friedman test\n",
    "        stat, p_value = friedmanchisquare(*[df_pivot[method] for method in df_pivot.columns])\n",
    "        friedman_results[dataset][metric] = p_value\n",
    "\n",
    "        if p_value < 0.05:\n",
    "            heuristics = df_pivot.columns\n",
    "            p_values = []\n",
    "            pairs = []\n",
    "\n",
    "            for i in range(len(heuristics)):\n",
    "                for j in range(i + 1, len(heuristics)):\n",
    "                    h1 = heuristics[i]\n",
    "                    h2 = heuristics[j]\n",
    "                    data_h1 = df_pivot[h1]\n",
    "                    data_h2 = df_pivot[h2]\n",
    "\n",
    "                    if np.array_equal(data_h1, data_h2):\n",
    "                        p_value = 1.0\n",
    "                    else:\n",
    "                        # Perform Wilcoxon signed-rank test\n",
    "                        try:\n",
    "                            stat, p_value = wilcoxon(data_h1, data_h2, zero_method='wilcox')\n",
    "                        except ValueError:\n",
    "                            p_value = np.nan\n",
    "                    p_values.append(p_value)\n",
    "                    pairs.append((h1, h2))\n",
    "\n",
    "            # Perform multiple comparisons correction (e.g., Bonferroni correction)\n",
    "            corrected_p_vals = smm.multipletests(p_values, alpha=0.05, method='bonferroni')[1]\n",
    "            pairwise_results[dataset][metric] = dict(zip(pairs, corrected_p_vals))\n",
    "\n",
    "# Initialize a dictionary to store ranks\n",
    "ranks = {dataset: {metric: {} for metric in metrics} for dataset in combined_df['dataset'].unique()}\n",
    "\n",
    "# Assign ranks based on significant differences\n",
    "for dataset in combined_df['dataset'].unique():\n",
    "    dataset_df = combined_df[combined_df['dataset'] == dataset]\n",
    "\n",
    "    for metric in metrics:\n",
    "        df_pivot = dataset_df.pivot(index=['prefix_length', 'desired_nr_of_cfs'], columns='heuristic', values=metric)\n",
    "\n",
    "        # Drop rows with any NaN values to ensure equal N for all groups\n",
    "        df_pivot = df_pivot.dropna()\n",
    "\n",
    "        if len(df_pivot.columns) < 2:\n",
    "            continue  # Skip if there are less than 2 methods to compare\n",
    "\n",
    "        methods = df_pivot.columns\n",
    "\n",
    "        if friedman_results[dataset][metric] < 0.05:\n",
    "            for method in methods:\n",
    "                ranks[dataset][metric][method] = 1  # Initial rank\n",
    "\n",
    "            for (h1, h2), corrected_p_val in pairwise_results[dataset][metric].items():\n",
    "                if corrected_p_val < 0.05:\n",
    "                    if df_pivot[h1].mean() < df_pivot[h2].mean():\n",
    "                        ranks[dataset][metric][h2] += 1\n",
    "                    else:\n",
    "                        ranks[dataset][metric][h1] += 1\n",
    "        else:\n",
    "            for method in methods:\n",
    "                ranks[dataset][metric][method] = 1  # Same rank if no significant difference\n",
    "\n",
    "# Create a DataFrame to store the ranks\n",
    "rank_table = pd.DataFrame(columns=['dataset', 'metric', 'heuristic', 'rank'])\n",
    "\n",
    "# Populate the DataFrame with ranks\n",
    "for dataset in ranks.keys():\n",
    "    for metric in ranks[dataset].keys():\n",
    "        for method, rank in ranks[dataset][metric].items():\n",
    "            rank_table = rank_table.append({\n",
    "                'dataset': dataset,\n",
    "                'metric': metric,\n",
    "                'heuristic': method,\n",
    "                'rank': rank\n",
    "            }, ignore_index=True)\n",
    "\n",
    "# Pivot the rank_table to show ranks for each dataset, heuristic, and metric\n",
    "pivot_table = rank_table.pivot_table(index=['dataset', 'heuristic'], columns='metric', values='rank')\n",
    "\n",
    "# Display the pivot table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3015039-9e2b-4547-8745-0c8124fcf354",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0c6164-7a10-425e-b7e3-ff28e43670d2",
   "metadata": {},
   "source": [
    "# Dataset wise boxplot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3f5cff-f43c-4727-95e1-4bb13250eaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "path = \"results/synthetic_data\"\n",
    "folders = [\"results/synthetic_data/10%\",\n",
    "           \"results/synthetic_data/25%\",\n",
    "           \"results/synthetic_data/50%\"]\n",
    "dfs = []\n",
    "for subdir, dirs, files in os.walk(path+'/'):\n",
    "    for file in files:\n",
    "        if 'cfeval' in file:\n",
    "            df = pd.read_csv(os.path.join(subdir,file))\n",
    "            df['alphabet_coverage'] = subdir.split('/')[-1]\n",
    "            dfs.append(df)\n",
    "final_df = pd.concat(dfs)\n",
    "\n",
    "\n",
    "prefixes = [7,9,11,13]\n",
    "df = final_df\n",
    "# Update 'heuristic' column where 'method' is 'genetic'\n",
    "df.loc[df['method'] == 'genetic_ltlf_baseline_operators', 'heuristic'] = 'genetic_ltlf_baseline_operators'\n",
    "\n",
    "# Update 'heuristic' column where 'method' is 'random'\n",
    "\n",
    "df = df[df['prefix_length'].isin(prefixes)]\n",
    "df = df.rename(columns={'sat_score':'trace fitness','distance_l2j':'distance','implausibility_sum':'implausibility'\n",
    "                                       ,'avg_nbr_changes_per_cf':'sparsity','diversity_l2j':'diversity'})\n",
    "all_data = df\n",
    "all_data['hit_rate'] = all_data['generated_cfs']/all_data['desired_nr_of_cfs']\n",
    "\n",
    "rows = 0 \n",
    "coverages = [\"10%\",\"25%\",\"50%\"]\n",
    "fig_1, axes = plt.subplots(nrows=len(coverages), ncols=7, figsize=(35, 16),sharey='col')\n",
    "\n",
    "for coverage in coverages:\n",
    "    df = all_data[all_data['alphabet_coverage'].str.contains(coverage)]\n",
    "    #df['optimization'].replace({'multiobjective_adapted':'AOMO','multiobjective_baseline':'BOMO',\n",
    "    #                           'single_adapted':'AOSO','single_baseline':'BOSO'},inplace=True)\n",
    "    df = df[\n",
    "        ['heuristic','prefix_length','desired_nr_of_cfs','distance', 'sparsity','implausibility','trace fitness','diversity','hit_rate','runtime']]\n",
    "    df_groupby = df.groupby(['heuristic', 'prefix_length','desired_nr_of_cfs']).mean(numeric_only=True)\n",
    "    # crate the figure and axes\n",
    "    #df_groupby.iloc[-32:-16,-1] *= 0.3\n",
    "    for j, i in enumerate(df_groupby.columns):\n",
    "        #df_groupby[[i]].unstack(level=0).plot(ax=axes[rows][j], legend=None, title=i,linewidth=5.0,\n",
    "        #                                      style=['--', '-', '--','-'],\n",
    "                                              #cmap=\"Accent\",\n",
    "        #                                      fontsize=18,color=['red','orange','green','blue']\n",
    "        #                                  )\n",
    "        medianprops = dict(linewidth=3, color='black')\n",
    "        bplot = df_groupby[[i]].boxplot(by='heuristic',ax=axes[rows][j], #legend=None, title=i,#,linewidth=5.0,\n",
    "                                      #style=['--', '-', '--','-'],\n",
    "                                      #cmap=\"Accent\",\n",
    "                                      patch_artist=True,fontsize=18,medianprops=medianprops,\n",
    "                                         return_type='both'#,color=['red','orange','green','blue']\n",
    "                                  )\n",
    "        colors=['red','orange','green','gray','magenta']\n",
    "        for row_key, (ax,row) in bplot.items():\n",
    "            ax.set_xlabel('')\n",
    "            for i,box in enumerate(row['boxes']):\n",
    "                box.set_facecolor(colors[i])\n",
    "\n",
    "\n",
    "    for ax in axes.flatten():\n",
    "        ax.yaxis.set_tick_params(labelleft=True,labelsize=22)\n",
    "        ax.set(xlabel=None)\n",
    "        ax.set(xticklabels=[])\n",
    "        ax.set_title(label=ax.title._text,fontsize=22,fontweight='bold')\n",
    "    axes[rows,3].set_title(\"Alphabet coverage \"+coverage+\"\\n\"+'satisfaction rate',fontweight=\"bold\",size=22)\n",
    "    axes[rows,3].set_ylim(0.3,1.1)\n",
    "    axes[rows,5].set_ylim(0.3,1.1)\n",
    "\n",
    "    rows += 1\n",
    "red_patch = mpatches.Patch(color='red', label='genetic',)\n",
    "orange_patch = mpatches.Patch(color='orange', label='genetic_ltlf_baseline_operators')\n",
    "green_patch = mpatches.Patch(color='green', label='h1.Outback')\n",
    "#blue_patch = mpatches.Patch(color='blue', label='h2.Highlander')\n",
    "gray_patch = mpatches.Patch(color='gray', label='h2.Pathfinder')\n",
    "magenta_patch = mpatches.Patch(color='magenta', label='h3.Freelander')\n",
    "fig_1.legend(handles=[red_patch,orange_patch,green_patch,gray_patch,magenta_patch],loc='upper center',\n",
    "        bbox_to_anchor=(0.5, 1.03),\n",
    "        ncol=6,prop={\"size\":27},fontsize=40)\n",
    "fig_1.suptitle('Claim Management',x=0.07,y=0.73,fontsize=40,fontweight='bold',rotation=90)\n",
    "#fig_1.savefig('/Users/andrei/Desktop/PhD/boxplots_overall_ecai_paper_synthetic_log.png', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14758120-2a4f-44d2-a3c7-893336cb9426",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "path = \"results/bpic2012_O_ACCEPTED-COMPLETE\"\n",
    "folders = [\"results/bpic2012_O_ACCEPTED-COMPLETE/10%\",\n",
    "           \"results/bpic2012_O_ACCEPTED-COMPLETE/25%\",\n",
    "           \"results/bpic2012_O_ACCEPTED-COMPLETE/50%\"\n",
    "          ]\n",
    "dfs = []\n",
    "for subdir, dirs, files in os.walk(path+'/'):\n",
    "    if subdir in folders:\n",
    "        for file in files:\n",
    "                if 'cfeval' in file:\n",
    "                        df = pd.read_csv(os.path.join(subdir,file))\n",
    "                        df['alphabet_coverage'] = subdir.split('/')[-1]\n",
    "                        dfs.append(df)\n",
    "final_df = pd.concat(dfs)\n",
    "\n",
    "\n",
    "prefixes = [20,25,30,35]\n",
    "df = final_df\n",
    "# Update 'heuristic' column where 'method' is 'genetic'\n",
    "df.loc[df['method'] == 'genetic_ltlf_baseline_operators', 'heuristic'] = 'genetic_ltlf_baseline_operators'\n",
    "\n",
    "df = df[df['prefix_length'].isin(prefixes)]\n",
    "df = df.rename(columns={'sat_score':'trace fitness','distance_l2j':'distance','implausibility_sum':'implausibility'\n",
    "                                       ,'avg_nbr_changes_per_cf':'sparsity','diversity_l2j':'diversity'})\n",
    "all_data = df\n",
    "all_data['hit_rate'] = all_data['generated_cfs']/all_data['desired_nr_of_cfs']\n",
    "\n",
    "rows = 0 \n",
    "coverages = [\"10%\",\"25%\",\n",
    "             \"50%\"\n",
    "            ]\n",
    "fig_1, axes = plt.subplots(nrows=len(coverages), ncols=7, figsize=(35, 16),sharey='col')\n",
    "\n",
    "for coverage in coverages:\n",
    "    df = all_data[all_data['alphabet_coverage'].str.contains(coverage)]\n",
    "    #df['optimization'].replace({'multiobjective_adapted':'AOMO','multiobjective_baseline':'BOMO',\n",
    "    #                           'single_adapted':'AOSO','single_baseline':'BOSO'},inplace=True)\n",
    "    df = df[\n",
    "        ['heuristic','prefix_length','desired_nr_of_cfs','distance', 'sparsity','implausibility','trace fitness','diversity','hit_rate','runtime']]\n",
    "    df_groupby = df.groupby(['heuristic', 'prefix_length','desired_nr_of_cfs']).mean(numeric_only=True)\n",
    "    # crate the figure and axes\n",
    "    #df_groupby.iloc[-32:-16,-1] *= 0.3\n",
    "    for j, i in enumerate(df_groupby.columns):\n",
    "        #df_groupby[[i]].unstack(level=0).plot(ax=axes[rows][j], legend=None, title=i,linewidth=5.0,\n",
    "        #                                      style=['--', '-', '--','-'],\n",
    "                                              #cmap=\"Accent\",\n",
    "        #                                      fontsize=18,color=['red','orange','green','blue']\n",
    "        #                                  )\n",
    "        medianprops = dict(linewidth=3, color='black')\n",
    "        bplot = df_groupby[[i]].boxplot(by='heuristic',ax=axes[rows][j], #legend=None, title=i,#,linewidth=5.0,\n",
    "                                      #style=['--', '-', '--','-'],\n",
    "                                      #cmap=\"Accent\",\n",
    "                                      patch_artist=True,fontsize=18,medianprops=medianprops,\n",
    "                                         return_type='both'#,color=['red','orange','green','blue']\n",
    "                                  )\n",
    "        colors=['red','orange','green','gray','magenta']\n",
    "        for row_key, (ax,row) in bplot.items():\n",
    "            ax.set_xlabel('')\n",
    "            for i,box in enumerate(row['boxes']):\n",
    "                box.set_facecolor(colors[i])\n",
    "\n",
    "\n",
    "    for ax in axes.flatten():\n",
    "        ax.yaxis.set_tick_params(labelleft=True,labelsize=22)\n",
    "        ax.set(xlabel=None)\n",
    "        ax.set(xticklabels=[])\n",
    "        ax.set_title(label=ax.title._text,fontsize=22,fontweight='bold')\n",
    "    axes[rows,3].set_title(\"Alphabet coverage \"+coverage+\"\\n\"+'satisfaction rate',fontweight=\"bold\",size=22)\n",
    "    axes[rows,3].set_ylim(0.3,1.1)\n",
    "    axes[rows,5].set_ylim(0.3,1.1)\n",
    "\n",
    "    rows += 1\n",
    "red_patch = mpatches.Patch(color='red', label='genetic',)\n",
    "orange_patch = mpatches.Patch(color='orange', label='genetic_ltlf_baseline_operators')\n",
    "green_patch = mpatches.Patch(color='green', label='h1.Outback')\n",
    "#blue_patch = mpatches.Patch(color='blue', label='h2.Highlander')\n",
    "gray_patch = mpatches.Patch(color='gray', label='h2.Pathfinder')\n",
    "magenta_patch = mpatches.Patch(color='magenta', label='h3.Freelander')\n",
    "fig_1.legend(handles=[red_patch,orange_patch,green_patch,gray_patch,magenta_patch],loc='upper center',\n",
    "        bbox_to_anchor=(0.5, 1.03),\n",
    "        ncol=6,prop={\"size\":27},fontsize=40)\n",
    "fig_1.suptitle('BPIC2012',x=0.07,y=0.73,fontsize=40,fontweight='bold',rotation=90)\n",
    "#fig_1.savefig('/Users/andrei/Desktop/PhD/boxplots_overall_ecai_paper_synthetic_log.png', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc862a7-ef43-49bf-bfcb-6e0b864f6959",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "path = \"results/BPIC17_O_ACCEPTED\"\n",
    "folders = [\"results/BPIC17_O_ACCEPTED/10%\",\n",
    "           \"results/BPIC17_O_ACCEPTED/25%\",\n",
    "           \"results/BPIC17_O_ACCEPTED/50%\"\n",
    "          ]\n",
    "dfs = []\n",
    "for subdir, dirs, files in os.walk(path+'/'):\n",
    "    if subdir in folders:\n",
    "        for file in files:\n",
    "                if 'cfeval' in file:\n",
    "                        df = pd.read_csv(os.path.join(subdir,file))\n",
    "                        df['alphabet_coverage'] = subdir.split('/')[-1]\n",
    "                        dfs.append(df)\n",
    "final_df = pd.concat(dfs)\n",
    "\n",
    "\n",
    "prefixes = [20,25,30,35]\n",
    "df = final_df\n",
    "# Update 'heuristic' column where 'method' is 'genetic'\n",
    "df.loc[df['method'] == 'genetic_ltlf_baseline_operators', 'heuristic'] = 'genetic_ltlf_baseline_operators'\n",
    "# Update 'heuristic' column where 'method' is 'random'\n",
    "\n",
    "df = df[df['prefix_length'].isin(prefixes)]\n",
    "df = df.rename(columns={'sat_score':'trace fitness','distance_l2j':'distance','implausibility_sum':'implausibility'\n",
    "                                       ,'avg_nbr_changes_per_cf':'sparsity','diversity_l2j':'diversity'})\n",
    "all_data = df\n",
    "all_data['hit_rate'] = all_data['generated_cfs']/all_data['desired_nr_of_cfs']\n",
    "\n",
    "rows = 0 \n",
    "coverages = [\"10%\",\"25%\",\n",
    "             \"50%\"\n",
    "            ]\n",
    "fig_1, axes = plt.subplots(nrows=len(coverages), ncols=7, figsize=(35, 16),sharey='col')\n",
    "\n",
    "for coverage in coverages:\n",
    "    df = all_data[all_data['alphabet_coverage'].str.contains(coverage)]\n",
    "    #df['optimization'].replace({'multiobjective_adapted':'AOMO','multiobjective_baseline':'BOMO',\n",
    "    #                           'single_adapted':'AOSO','single_baseline':'BOSO'},inplace=True)\n",
    "    df = df[\n",
    "        ['heuristic','prefix_length','desired_nr_of_cfs','distance', 'sparsity','implausibility','trace fitness','diversity','hit_rate','runtime']]\n",
    "    df_groupby = df.groupby(['heuristic', 'prefix_length','desired_nr_of_cfs']).mean(numeric_only=True)\n",
    "    # crate the figure and axes\n",
    "    #df_groupby.iloc[-32:-16,-1] *= 0.3\n",
    "    for j, i in enumerate(df_groupby.columns):\n",
    "        #df_groupby[[i]].unstack(level=0).plot(ax=axes[rows][j], legend=None, title=i,linewidth=5.0,\n",
    "        #                                      style=['--', '-', '--','-'],\n",
    "                                              #cmap=\"Accent\",\n",
    "        #                                      fontsize=18,color=['red','orange','green','blue']\n",
    "        #                                  )\n",
    "        medianprops = dict(linewidth=3, color='black')\n",
    "        bplot = df_groupby[[i]].boxplot(by='heuristic',ax=axes[rows][j], #legend=None, title=i,#,linewidth=5.0,\n",
    "                                      #style=['--', '-', '--','-'],\n",
    "                                      #cmap=\"Accent\",\n",
    "                                      patch_artist=True,fontsize=18,medianprops=medianprops,\n",
    "                                         return_type='both'#,color=['red','orange','green','blue']\n",
    "                                  )\n",
    "        colors=['red','orange','green','gray','magenta']\n",
    "        for row_key, (ax,row) in bplot.items():\n",
    "            ax.set_xlabel('')\n",
    "            for i,box in enumerate(row['boxes']):\n",
    "                box.set_facecolor(colors[i])\n",
    "\n",
    "\n",
    "    for ax in axes.flatten():\n",
    "        ax.yaxis.set_tick_params(labelleft=True,labelsize=22)\n",
    "        ax.set(xlabel=None)\n",
    "        ax.set(xticklabels=[])\n",
    "        ax.set_title(label=ax.title._text,fontsize=22,fontweight='bold')\n",
    "    axes[rows,3].set_title(\"Alphabet coverage \"+coverage+\"\\n\"+'satisfaction rate',fontweight=\"bold\",size=22)\n",
    "    axes[rows,3].set_ylim(0.3,1.1)\n",
    "    axes[rows,5].set_ylim(0.3,1.1)\n",
    "\n",
    "    rows += 1\n",
    "red_patch = mpatches.Patch(color='red', label='genetic',)\n",
    "orange_patch = mpatches.Patch(color='orange', label='genetic_ltlf_baseline_operators')\n",
    "green_patch = mpatches.Patch(color='green', label='h1.Outback')\n",
    "#blue_patch = mpatches.Patch(color='blue', label='h2.Highlander')\n",
    "gray_patch = mpatches.Patch(color='gray', label='h2.Pathfinder')\n",
    "magenta_patch = mpatches.Patch(color='magenta', label='h3.Freelander')\n",
    "fig_1.legend(handles=[red_patch,orange_patch,green_patch,gray_patch,magenta_patch],loc='upper center',\n",
    "        bbox_to_anchor=(0.5, 1.03),\n",
    "        ncol=6,prop={\"size\":27},fontsize=40)\n",
    "fig_1.suptitle('BPIC17_O_ACCEPTED',x=0.07,y=0.73,fontsize=40,fontweight='bold',rotation=90)\n",
    "#fig_1.savefig('/Users/andrei/Desktop/PhD/boxplots_overall_ecai_paper_synthetic_log.png', bbox_inches='tight')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AAAI2025-temporal-constrained-counterfactuals",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
